# -*- coding: utf-8 -*-
"""PipelineWork.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1b6XV-UBpqtGMsQS31KmGWH2qTjsb8f8z
"""

import torch
import torch.nn as nn
from torch.utils import data
import torch.nn.functional as F
import numpy as np
import torchvision
import torchvision.transforms as transforms
from torch.optim.lr_scheduler import MultiStepLR, CosineAnnealingLR

from Model import *


class Cutout(object):
    """Randomly mask out one or more patches from an image.
    Args:
        n_holes (int): Number of patches to cut out of each image.
        length (int): The length (in pixels) of each square patch.
    """
    def __init__(self, n_holes = 1, length=16):
        self.n_holes = n_holes
        self.length = length

    def __call__(self, img):
        """
        Args:
            img (Tensor): Tensor image of size (C, H, W).
        Returns:
            Tensor: Image with n_holes of dimension length x length cut out of it.
        """
        h = img.size(1)
        w = img.size(2)

        mask = np.ones((h, w), np.float32)

        for n in range(self.n_holes):
            y = np.random.randint(h)
            x = np.random.randint(w)

            y1 = np.clip(y - self.length // 2, 0, h)
            y2 = np.clip(y + self.length // 2, 0, h)
            x1 = np.clip(x - self.length // 2, 0, w)
            x2 = np.clip(x + self.length // 2, 0, w)

            mask[y1: y2, x1: x2] = 0.

        mask = torch.from_numpy(mask)
        mask = mask.expand_as(img)
        img = img * mask

        return img


def train(model, train_X, loss_func, optimizer):
    model.train()
    total_loss = 0
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    for i, (x, y) in enumerate(train_X):
        x = x.to(device)
        y = y.to(device)
        outputs = model(x)
        loss = loss_func(outputs, y)
        # backward and optimize
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        total_loss += loss.item() * x.shape[0]
        if (i + 1) % 300 == 0:
            print("Step [{}/{}] Train Loss: {:.4f}".format(i + 1, len(train_X), loss.item()))

    print(total_loss / len(train_X.dataset))  # 其实loss计算有点小问题
    return total_loss / len(train_X.dataset)


def predict(model,test_X):
    model.eval()
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    top1_acc = top5_acc = 0
    with torch.no_grad():
        for i , (x,y) in enumerate(test_X):
            x = x.to(device)
            y = y.to(device)
            output = model(x)
            _, indice = output.topk(5, -1, True, sorted= True)
            top1_acc += torch.eq(indice[:, 0], y).sum().item()
            top5_acc += torch.eq(indice , y.view(-1,1)).sum().item()
    return top1_acc/len(test_X.dataset) , top5_acc/len(test_X.dataset)


"""# 调节不同 N_holes / Length , 粗略得到 CUTOUT 最优值"""

# Parameters 
# 调节以选出最优！！！
CUTOUT = False
N_holes = 1
Length = 16

train_transform = transforms.Compose([
    transforms.RandomHorizontalFlip(),
    transforms.RandomCrop(32, 4),
    transforms.ToTensor(),
    transforms.Normalize( mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225]),])

# cutout or not
if CUTOUT:
    train_transform.transforms.append(Cutout(n_holes=N_holes, length=Length))

normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225])

train_dataset = torchvision.datasets.CIFAR10(root='cifar',download=True ,train=True, transform=train_transform)
test_dataset = torchvision.datasets.CIFAR10(root='cifar',download=True ,train=False, transform=transforms.Compose([
    transforms.ToTensor(),
    normalize, ]))


# train_loader
batch_size = 128
num_workers = 2
trainLoader = torch.utils.data.DataLoader(train_dataset,
              batch_size=batch_size, shuffle=True,
              num_workers=num_workers, pin_memory=True,
              drop_last=True,) # collate_fn=collator
testLoader = torch.utils.data.DataLoader(test_dataset,
          batch_size= 512 , shuffle=False,
          num_workers=num_workers, pin_memory=True,
          drop_last=False)



# from PIL import Image
for imgs in trainLoader:
  img = imgs[0]
  print( img[0].shape)
  arrayImg = img[0].numpy()
  import matplotlib.pyplot as plt
  plt.figure("Image")
  plt.imshow(arrayImg[0])
  plt.axis('on')
  plt.title('image')
  plt.show()
  break

date = '621'
if CUTOUT:
  ss = 'Cutout' + str(N_holes) + '_' + str(Length) 
  signal = 'ResNet18_' + date + ss + '.pth'
else:
  signal = 'ResNet18_' + date + '.pth'

PATH = './drive/MyDrive/' + signal
print(PATH)

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
model = ResNet(BasicBlock, [2,2,2,2], 10)
# model = ResNet(BasicBlock, [2,2,2,2], 10 , reduce = 2)
model.to(device)
# copy from github
# optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay= 5e-4,nesterov=True)
# scheduler = MultiStepLR(optimizer, milestones=[60,120,160,180], gamma=0.5)

optimizer = torch.optim.SGD(model.parameters(), lr=0.2, momentum=0.9, weight_decay=1e-4,nesterov=True)
scheduler = CosineAnnealingLR(optimizer, 200, 0)

loss_func = nn.CrossEntropyLoss()
# scheduler = MultiStepLR(optimizer, milestones=[30,60,90,120,150,160,180], gamma=0.7)
print('refresh')
best_accuracy = None

# train
# 三、 训练
import time
start = time.time()
Iter_Time = 200
loss_train = np.zeros(Iter_Time)
test_acc= np.zeros(Iter_Time)
test_5acc= np.zeros(Iter_Time)
train_acc = np.zeros(Iter_Time)
print('start to train' + '*'*20)
if best_accuracy is None:
  best_accuracy = 0   
for epoch in range(Iter_Time):
    loss = train(model= model, train_X=trainLoader, loss_func=loss_func,optimizer=optimizer)
    loss_train[epoch] = loss
    top1 , top5 = predict(model=model, test_X =testLoader)
    test_acc[epoch] = top1
    test_5acc[epoch] = top5
    print('训练轮次',epoch, 'loss:' , loss ,'top1 & top5:' ,top1 , top5 , '总训练时间:', time.time() - start)
    scheduler.step()

    if best_accuracy < top1:
      best_accuracy = top1 
      torch.save(model.state_dict(),PATH)
      print('Model is saved in epoch_%d_accuracy_%f'%(epoch, top1 ) )

loss_acc = np.append(loss_train , test_acc)
txtPath = './drive/MyDrive/lossAndAcc/'
np.savetxt( txtPath + signal + '.txt' , loss_acc)