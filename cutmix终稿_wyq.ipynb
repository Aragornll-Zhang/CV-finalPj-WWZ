{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutmix(batch,alpha=1):\n",
    "    inputs,labels = batch\n",
    "    indices = torch.randperm(inputs.size(0))\n",
    "    shuffled_inputs = inputs[indices]\n",
    "    shuffled_labels = labels[indices]\n",
    "\n",
    "    weight,height= inputs.shape[2:]\n",
    "    lamb = np.random.beta(alpha, alpha)\n",
    "\n",
    "    rx=np.random.uniform(0, weight)\n",
    "    ry=np.random.uniform(0, height)\n",
    "\n",
    "    rw=weight*np.sqrt(1-lamb)\n",
    "    rh=height*np.sqrt(1-lamb)\n",
    "\n",
    "    x0 = int(np.round(max(rx - rw / 2, 0)))\n",
    "    x1 = int(np.round(min(rx + rw / 2, weight)))\n",
    "    y0 = int(np.round(max(ry - rh / 2, 0)))\n",
    "    y1 = int(np.round(min(ry + rh / 2, height)))\n",
    "\n",
    "    inputs[:, :, y0:y1, x0:x1] = shuffled_inputs[:, :, y0:y1, x0:x1]\n",
    "    labels = (labels, shuffled_labels, lamb)\n",
    "\n",
    "    return inputs,labels\n",
    "\n",
    "class CutMixCollator:\n",
    "    def __init__(self, alpha):\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        batch = torch.utils.data.dataloader.default_collate(batch)\n",
    "        batch = cutmix(batch, self.alpha)\n",
    "        return batch\n",
    "\n",
    "class CutMixCriterion:\n",
    "    def __init__(self, reduction):\n",
    "        self.criterion = nn.CrossEntropyLoss(reduction=reduction)\n",
    "\n",
    "    def __call__(self, preds, targets):\n",
    "        targets1, targets2, lam = targets\n",
    "        return lam * self.criterion(\n",
    "            preds, targets1) + (1 - lam) * self.criterion(preds, targets2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loader(batch_size=128,num_workers=4,cutmix=True,alpha=1):\n",
    "    if cutmix==True:\n",
    "        collator = CutMixCollator(alpha)\n",
    "    else:\n",
    "        collator = torch.utils.data.dataloader.default_collate\n",
    "\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    train_dataset = datasets.CIFAR10(root='cifar', train=True, transform=transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                    transforms.RandomCrop(32, 4),\n",
    "                    transforms.ToTensor(),\n",
    "                    normalize,]), download=True)\n",
    "      \n",
    "    dev_dataset=datasets.CIFAR10(root='cifar', train=False, transform=transforms.Compose([                                                                    \n",
    "                transforms.ToTensor(),\n",
    "                normalize,]))\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset,      \n",
    "                       batch_size=batch_size, shuffle=True,\n",
    "                       num_workers=num_workers, pin_memory=True,\n",
    "                       drop_last=True,collate_fn=collator)\n",
    "    \n",
    "    dev_dataloader = torch.utils.data.DataLoader( dev_dataset, \n",
    "                     batch_size=batch_size, shuffle=False,\n",
    "                     num_workers=num_workers, pin_memory=True,\n",
    "                     drop_last=False)\n",
    "    return train_dataloader,dev_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataloader,dev_dataloader=get_loader(batch_size=128,num_workers=4,cutmix=True,alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(in_planes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = conv3x3(3,64)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available() \n",
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ResNet(BasicBlock, [2,2,2,2], 10)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/miniconda3/envs/python_gpu/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "criterion1 = CutMixCriterion(reduction='mean')\n",
    "criterion2 = nn.CrossEntropyLoss(size_average=True)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.2, momentum=0.9, weight_decay=1e-4,nesterov=True)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, 300, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingloss=[]\n",
    "trainingacc=[]\n",
    "valloss=[]\n",
    "valacc=[]\n",
    "valacc5=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_logger(filename, verbosity=1, name=None):\n",
    "    level_dict = {0: logging.DEBUG, 1: logging.INFO, 2: logging.WARNING}\n",
    "    formatter = logging.Formatter(\n",
    "        \"[%(asctime)s][%(filename)s][line:%(lineno)d][%(levelname)s] %(message)s\"\n",
    "    )\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(level_dict[verbosity])\n",
    "\n",
    "    fh = logging.FileHandler(filename, \"w\")\n",
    "    fh.setFormatter(formatter)\n",
    "    logger.addHandler(fh)\n",
    "\n",
    "    sh = logging.StreamHandler()\n",
    "    sh.setFormatter(formatter)\n",
    "    logger.addHandler(sh)\n",
    "\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-06-19 00:53:55,179][<ipython-input-26-b7fe465fc713>][line:2][INFO] start training!\n",
      "[2021-06-19 00:53:55,179][<ipython-input-26-b7fe465fc713>][line:2][INFO] start training!\n"
     ]
    }
   ],
   "source": [
    "logger = get_logger('cutmix终稿3/exp.log')\n",
    "logger.info('start training!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0_25.600%:  Training average Loss: 3.040181\n",
      "Epoch 0_51.200%:  Training average Loss: 2.613891\n",
      "Epoch 0_76.800%:  Training average Loss: 2.468011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-06-19 00:54:27,998][<ipython-input-27-94dce6441585>][line:50][INFO] Epoch 0 :  Training average Loss: 2.389646, Training accuracy: 16.602943%,Total Time:24.414154\n",
      "[2021-06-19 00:54:27,998][<ipython-input-27-94dce6441585>][line:50][INFO] Epoch 0 :  Training average Loss: 2.389646, Training accuracy: 16.602943%,Total Time:24.414154\n",
      "[2021-06-19 00:54:29,710][<ipython-input-27-94dce6441585>][line:92][INFO] Epoch 0 :  Verification average Loss: 1.949977, Verification accuracy: 22.850000%,Verification 5 accuracy: 81.050000%,Total Time:26.126561\n",
      "[2021-06-19 00:54:29,710][<ipython-input-27-94dce6441585>][line:92][INFO] Epoch 0 :  Verification average Loss: 1.949977, Verification accuracy: 22.850000%,Verification 5 accuracy: 81.050000%,Total Time:26.126561\n",
      "[2021-06-19 00:54:33,656][<ipython-input-27-94dce6441585>][line:102][INFO] Model is saved in cutmix终稿3/epoch_0_accuracy_0.228500\n",
      "[2021-06-19 00:54:33,656][<ipython-input-27-94dce6441585>][line:102][INFO] Model is saved in cutmix终稿3/epoch_0_accuracy_0.228500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1_25.600%:  Training average Loss: 2.145577\n",
      "Epoch 1_51.200%:  Training average Loss: 2.131984\n",
      "Epoch 1_76.800%:  Training average Loss: 2.124279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-06-19 00:54:59,280][<ipython-input-27-94dce6441585>][line:50][INFO] Epoch 1 :  Training average Loss: 2.103731, Training accuracy: 21.387986%,Total Time:55.696569\n",
      "[2021-06-19 00:54:59,280][<ipython-input-27-94dce6441585>][line:50][INFO] Epoch 1 :  Training average Loss: 2.103731, Training accuracy: 21.387986%,Total Time:55.696569\n",
      "[2021-06-19 00:55:01,956][<ipython-input-27-94dce6441585>][line:92][INFO] Epoch 1 :  Verification average Loss: 1.764314, Verification accuracy: 33.980000%,Verification 5 accuracy: 87.820000%,Total Time:58.372976\n",
      "[2021-06-19 00:55:01,956][<ipython-input-27-94dce6441585>][line:92][INFO] Epoch 1 :  Verification average Loss: 1.764314, Verification accuracy: 33.980000%,Verification 5 accuracy: 87.820000%,Total Time:58.372976\n",
      "[2021-06-19 00:55:08,568][<ipython-input-27-94dce6441585>][line:102][INFO] Model is saved in cutmix终稿3/epoch_1_accuracy_0.339800\n",
      "[2021-06-19 00:55:08,568][<ipython-input-27-94dce6441585>][line:102][INFO] Model is saved in cutmix终稿3/epoch_1_accuracy_0.339800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2_25.600%:  Training average Loss: 2.054627\n",
      "Epoch 2_51.200%:  Training average Loss: 2.050564\n",
      "Epoch 2_76.800%:  Training average Loss: 2.045203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-06-19 00:55:32,830][<ipython-input-27-94dce6441585>][line:50][INFO] Epoch 2 :  Training average Loss: 2.023024, Training accuracy: 25.940451%,Total Time:89.246212\n",
      "[2021-06-19 00:55:32,830][<ipython-input-27-94dce6441585>][line:50][INFO] Epoch 2 :  Training average Loss: 2.023024, Training accuracy: 25.940451%,Total Time:89.246212\n",
      "[2021-06-19 00:55:34,478][<ipython-input-27-94dce6441585>][line:92][INFO] Epoch 2 :  Verification average Loss: 1.637610, Verification accuracy: 38.160000%,Verification 5 accuracy: 89.780000%,Total Time:90.894734\n",
      "[2021-06-19 00:55:34,478][<ipython-input-27-94dce6441585>][line:92][INFO] Epoch 2 :  Verification average Loss: 1.637610, Verification accuracy: 38.160000%,Verification 5 accuracy: 89.780000%,Total Time:90.894734\n",
      "[2021-06-19 00:55:38,393][<ipython-input-27-94dce6441585>][line:102][INFO] Model is saved in cutmix终稿3/epoch_2_accuracy_0.381600\n",
      "[2021-06-19 00:55:38,393][<ipython-input-27-94dce6441585>][line:102][INFO] Model is saved in cutmix终稿3/epoch_2_accuracy_0.381600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3_25.600%:  Training average Loss: 2.007472\n",
      "Epoch 3_51.200%:  Training average Loss: 1.996073\n",
      "Epoch 3_76.800%:  Training average Loss: 1.995265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-06-19 00:56:02,857][<ipython-input-27-94dce6441585>][line:50][INFO] Epoch 3 :  Training average Loss: 1.969253, Training accuracy: 28.746775%,Total Time:119.273791\n",
      "[2021-06-19 00:56:02,857][<ipython-input-27-94dce6441585>][line:50][INFO] Epoch 3 :  Training average Loss: 1.969253, Training accuracy: 28.746775%,Total Time:119.273791\n",
      "[2021-06-19 00:56:04,509][<ipython-input-27-94dce6441585>][line:92][INFO] Epoch 3 :  Verification average Loss: 1.493865, Verification accuracy: 43.640000%,Verification 5 accuracy: 92.560000%,Total Time:120.925516\n",
      "[2021-06-19 00:56:04,509][<ipython-input-27-94dce6441585>][line:92][INFO] Epoch 3 :  Verification average Loss: 1.493865, Verification accuracy: 43.640000%,Verification 5 accuracy: 92.560000%,Total Time:120.925516\n",
      "[2021-06-19 00:56:08,467][<ipython-input-27-94dce6441585>][line:102][INFO] Model is saved in cutmix终稿3/epoch_3_accuracy_0.436400\n",
      "[2021-06-19 00:56:08,467][<ipython-input-27-94dce6441585>][line:102][INFO] Model is saved in cutmix终稿3/epoch_3_accuracy_0.436400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4_25.600%:  Training average Loss: 1.958737\n",
      "Epoch 4_51.200%:  Training average Loss: 1.952347\n",
      "Epoch 4_76.800%:  Training average Loss: 1.947876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-06-19 00:56:33,052][<ipython-input-27-94dce6441585>][line:50][INFO] Epoch 4 :  Training average Loss: 1.916666, Training accuracy: 31.616069%,Total Time:149.469056\n",
      "[2021-06-19 00:56:33,052][<ipython-input-27-94dce6441585>][line:50][INFO] Epoch 4 :  Training average Loss: 1.916666, Training accuracy: 31.616069%,Total Time:149.469056\n",
      "[2021-06-19 00:56:34,707][<ipython-input-27-94dce6441585>][line:92][INFO] Epoch 4 :  Verification average Loss: 1.415240, Verification accuracy: 47.210000%,Verification 5 accuracy: 93.450000%,Total Time:151.123877\n",
      "[2021-06-19 00:56:34,707][<ipython-input-27-94dce6441585>][line:92][INFO] Epoch 4 :  Verification average Loss: 1.415240, Verification accuracy: 47.210000%,Verification 5 accuracy: 93.450000%,Total Time:151.123877\n",
      "[2021-06-19 00:56:38,653][<ipython-input-27-94dce6441585>][line:102][INFO] Model is saved in cutmix终稿3/epoch_4_accuracy_0.472100\n",
      "[2021-06-19 00:56:38,653][<ipython-input-27-94dce6441585>][line:102][INFO] Model is saved in cutmix终稿3/epoch_4_accuracy_0.472100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5_25.600%:  Training average Loss: 1.894223\n"
     ]
    }
   ],
   "source": [
    "\n",
    "epoch=300\n",
    "best_accuracy=0.0\n",
    "es=0\n",
    "start_time=time.time()\n",
    "for i in range(epoch):\n",
    "    model.train()\n",
    "    total_loss=0.0\n",
    "    accuracy=0.0\n",
    "    total_correct=0.0\n",
    "    total_data_num = len(train_dataloader.dataset)\n",
    "    steps = 0.0\n",
    "    #训练\n",
    "    for batch in train_dataloader:\n",
    "        steps+=1\n",
    "        optimizer.zero_grad() \n",
    "        # 取数据\n",
    "        inputs, labels = batch\n",
    "        inputs = inputs.to(device)\n",
    "        labels, shuffled_labels, lamb=labels\n",
    "        labels=(labels.to(device), shuffled_labels.to(device), lamb)\n",
    "        #targets1, targets2, lam = targets\n",
    "        #, labels.to(device)  # 将输入和目标在每一步都送入GPU\n",
    "        outputs = model(inputs)\n",
    "        #_, outputs = torch.max(outputs.data, 1)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion1(outputs, labels).to(device)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()  \n",
    "\n",
    "        total_loss = total_loss + loss.item() \n",
    "\n",
    "        #计算正确率\n",
    "        labels, shuffled_labels, lamb=labels\n",
    "        correct1 = (torch.max(outputs, dim=1)[1]  #get the indices\n",
    "                   .view(labels.size()) == labels).sum()\n",
    "        correct2 = (torch.max(outputs, dim=1)[1]  #get the indices\n",
    "                   .view(shuffled_labels.size()) == shuffled_labels).sum()\n",
    "\n",
    "        correct = (lamb * correct1.item() + (1 - lamb) * correct2.item()) \n",
    "\n",
    "        total_correct = total_correct + correct\n",
    "\n",
    " \n",
    "        if steps%100==0:\n",
    "            print(\"Epoch %d_%.3f%%:  Training average Loss: %f\"\n",
    "                      %(i, steps * train_dataloader.batch_size*100/len(train_dataloader.dataset),total_loss/steps))\n",
    "    logger.info(\"Epoch %d :  Training average Loss: %f, Training accuracy: %f%%,Total Time:%f\"\n",
    "      %(i, total_loss/steps, total_correct*100/total_data_num,time.time()-start_time))   \n",
    "    trainingloss.append(total_loss/steps)\n",
    "    trainingacc.append(total_correct/total_data_num) \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #验证\n",
    "    scheduler.step()\n",
    "    model.eval()\n",
    "    total_loss=0.0\n",
    "    accuracy=0.0\n",
    "    total_correct=0.0\n",
    "    total_correctk=0.0\n",
    "    total_data_num = len(dev_dataloader.dataset)\n",
    "    steps = 0.0    \n",
    "    for batch in dev_dataloader:\n",
    "        steps+=1\n",
    "        inputs, labels = batch\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # 将输入和目标在每一步都送入GPU\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion2(outputs, labels)  \n",
    "        total_loss = total_loss + loss.item() \n",
    "        correct = (torch.max(outputs, dim=1)[1]  #get the indices\n",
    "                   .view(labels.size()) == labels).sum()\n",
    "        total_correct = total_correct + correct.item()\n",
    "\n",
    "        maxk = max((1,5))\n",
    "        yresize = labels.view(-1,1)\n",
    "        _, pred = outputs.topk(maxk, 1, True, True)\n",
    "\n",
    "        correctk = torch.eq(pred, yresize).sum()\n",
    "\n",
    "        #correct = (torch.max(outputs, dim=1)[1]  #get the indices\n",
    "                   #.view(labels.size()) == labels).sum()\n",
    "        total_correctk = total_correctk + correctk.item()\n",
    "        \n",
    "    logger.info(\"Epoch %d :  Verification average Loss: %f, Verification accuracy: %f%%,Verification 5 accuracy: %f%%,Total Time:%f\"\n",
    "      %(i, total_loss/steps, total_correct*100/total_data_num,total_correctk*100/total_data_num,time.time()-start_time))  \n",
    "    #print(\"Epoch %d :  Verification 5 accuracy: %f%%,Total Time:%f\"\n",
    "      #%(i,  total_correctk*100/total_data_num,time.time()-start_time))  \n",
    "    valloss.append(total_loss/steps)\n",
    "    valacc.append(total_correct/total_data_num) \n",
    "    valacc5.append(total_correctk/total_data_num) \n",
    "    if best_accuracy < total_correct/total_data_num :\n",
    "        es = 0\n",
    "        best_accuracy =total_correct/total_data_num \n",
    "        torch.save(model,'cutmix终稿3/epoch_%d_accuracy_%f'%(i,total_correct/total_data_num))\n",
    "        logger.info('Model is saved in cutmix终稿3/epoch_%d_accuracy_%f'%(i,total_correct/total_data_num))\n",
    "        #torch.cuda.empty_cache()\n",
    "    #torch.save(model.state_dict(), 'cutmix/epoch_%d_accuracy_%f.pkl'%(i,total_correct/total_data_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingloss=pd.DataFrame(data=trainingloss)\n",
    "trainingloss.to_csv('cutmix终稿3/trainingloss.csv',encoding='utf-8')\n",
    "\n",
    "trainingacc=pd.DataFrame(data=trainingacc)\n",
    "trainingacc.to_csv('cutmix终稿3/trainingacc.csv',encoding='utf-8')\n",
    "\n",
    "valloss=pd.DataFrame(data=valloss)\n",
    "valloss.to_csv('cutmix终稿3/valloss.csv',encoding='utf-8')\n",
    "\n",
    "valacc=pd.DataFrame(data=valacc)\n",
    "valacc.to_csv('cutmix终稿3/valacc.csv',encoding='utf-8')\n",
    "\n",
    "valacc5=pd.DataFrame(data=valacc5)\n",
    "valacc5.to_csv('cutmix终稿3/valacc5.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.mkdir('cutmix终稿3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python_gpu]",
   "language": "python",
   "name": "conda-env-python_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
